{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4b7d86-d633-4f79-b96a-5fbace03e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/son/Desktop/Research/simple-faster-rcnn-pytorch/model/utils/nms/non_maximum_suppression.py:12: UserWarning: \n",
      "    the python code for non_maximum_suppression is about 2x slow\n",
      "    It is strongly recommended to build cython code:\n",
      "    `cd model/utils/nms/; python3 build.py build_ext --inplace\n",
      "  warnings.warn('''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as tvtsf\n",
    "from skimage import transform as sktsf\n",
    "from data.util import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trainer import VictimFasterRCNNTrainer\n",
    "from utils import array_tool as at\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9756949-00e1-4037-945c-edcb7fcf6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, dtype=np.float32, color=True):\n",
    "    \"\"\"Read an image from a file.\n",
    "\n",
    "    This function reads an image from given file. The image is CHW format and\n",
    "    the range of its value is :math:`[0, 255]`. If :obj:`color = True`, the\n",
    "    order of the channels is RGB.\n",
    "\n",
    "    Args:\n",
    "        path (str): A path of image file.\n",
    "        dtype: The type of array. The default value is :obj:`~numpy.float32`.\n",
    "        color (bool): This option determines the number of channels.\n",
    "            If :obj:`True`, the number of channels is three. In this case,\n",
    "            the order of the channels is RGB. This is the default behaviour.\n",
    "            If :obj:`False`, this function returns a grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        ~numpy.ndarray: An image.\n",
    "    \"\"\"\n",
    "\n",
    "    f = Image.open(path)\n",
    "    try:\n",
    "        if color:\n",
    "            img = f.convert('RGB')\n",
    "        else:\n",
    "            img = f.convert('P')\n",
    "        img = np.asarray(img, dtype=dtype)\n",
    "    finally:\n",
    "        if hasattr(f, 'close'):\n",
    "            f.close()\n",
    "\n",
    "    if img.ndim == 2:\n",
    "        # reshape (H, W) -> (1, H, W)\n",
    "        return img[np.newaxis]\n",
    "    else:\n",
    "        # transpose (H, W, C) -> (C, H, W)\n",
    "        return img.transpose((2, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366e530-581a-4078-977d-8d34251ca9dd",
   "metadata": {},
   "source": [
    "# Dataset for WIDER FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f438caf-cde5-41b8-b609-d1e6d866fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WIDERBboxDataset:\n",
    "    def __init__(self, path_to_label, path_to_image, fname):\n",
    "        self.path_to_label = path_to_label\n",
    "        self.path_to_image = path_to_image\n",
    "        self.f = scipy.io.loadmat(os.path.join(path_to_label, fname))\n",
    "        self.event_list = self.f.get('event_list')\n",
    "        self.file_list = self.f.get('file_list')\n",
    "        self.face_bbx_list = self.f.get('face_bbx_list')\n",
    "        self.label_names = WIDER_BBOX_LABEL_NAMES\n",
    "        self.im_list, self.bbox_list = self.get_img_list()\n",
    "        # ipdb.set_trace()\n",
    "        self.is_difficult = False\n",
    "\n",
    "    def get_img_list(self):\n",
    "        im_list = []\n",
    "        bbox_list = []\n",
    "        for event_idx, event in enumerate(self.event_list):\n",
    "            directory = event[0][0]\n",
    "            for im_idx, im in enumerate(self.file_list[event_idx][0]):\n",
    "                im_name = im[0][0]\n",
    "                im_list.append(os.path.join(self.path_to_image, directory,\\\n",
    "                        im_name + '.jpg'))\n",
    "                face_bbx = self.face_bbx_list[event_idx][0][im_idx][0]\n",
    "                bbox_list.append(face_bbx)\n",
    "        return im_list,bbox_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_list)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        \"\"\"Returns the i-th example.\n",
    "        Returns a color image and bounding boxes. The image is in CHW format.\n",
    "        The returned image is RGB.\n",
    "\n",
    "        Args:\n",
    "            i (int): The index of the example.\n",
    "\n",
    "        Returns:\n",
    "            tuple of an image and bounding boxes\n",
    "        \"\"\"\n",
    "        # Load a image\n",
    "        img_file = self.im_list[i]\n",
    "        face_bbx = self.bbox_list[i]\n",
    "        img = read_image(img_file, color=True)\n",
    "        bboxes = []\n",
    "        label = []\n",
    "        difficult = []\n",
    "        for i in range(face_bbx.shape[0]):\n",
    "            xmin = int(face_bbx[i][0])\n",
    "            ymin = int(face_bbx[i][1])\n",
    "            xmax = int(face_bbx[i][2]) + xmin\n",
    "            ymax = int(face_bbx[i][3]) + ymin\n",
    "            bboxes.append((ymin, xmin, ymax, xmax))\n",
    "            label.append(WIDER_BBOX_LABEL_NAMES.index('Face'))\n",
    "            difficult.append(self.is_difficult)\n",
    "        bboxes = np.stack(bboxes).astype(np.float32)\n",
    "        label = np.stack(label).astype(np.int32)\n",
    "        difficult = np.array(difficult, dtype=np.bool_).astype(np.uint8)  # PyTorch don't support np.bool\n",
    "        return img, bboxes, label, difficult\n",
    "\n",
    "    __getitem__ = get_example\n",
    "\n",
    "\n",
    "WIDER_BBOX_LABEL_NAMES = (\n",
    "    'Face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fd6264-95da-4fed-bb33-95d936769aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.WIDERBboxDataset at 0x7f1c40138610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wider_label_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/wider_face_split'\n",
    "wider_data_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/WIDER_train/images'\n",
    "wider_fname_mat = 'wider_face_train'\n",
    "\n",
    "# Dataset\n",
    "db = WIDERBboxDataset(wider_label_dir, wider_data_dir, wider_fname_mat)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc811a4b-1520-48b5-8a8b-76740c932f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(db.get_example(1)[0].transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f2457-5484-4859-bf09-e47fff004205",
   "metadata": {},
   "source": [
    "# Wrapper Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462735e3-06d9-4288-969a-f913990594be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_normalize(img):\n",
    "    \"\"\"\n",
    "    https://github.com/pytorch/vision/issues/223\n",
    "    return appr -1~1 RGB\n",
    "    \"\"\"\n",
    "    # normalize = tvtsf.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                             std=[0.229, 0.224, 0.225])\n",
    "    normalize = tvtsf.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                std=[0.5, 0.5, 0.5])\n",
    "    img = normalize(t.from_numpy(img))\n",
    "    return img.numpy()\n",
    "\n",
    "def preprocess(img, min_size=600, max_size=1000):\n",
    "    \"\"\"Preprocess an image for feature extraction.\n",
    "\n",
    "    The length of the shorter edge is scaled to :obj:`self.min_size`.\n",
    "    After the scaling, if the length of the longer edge is longer than\n",
    "    :param min_size:\n",
    "    :obj:`self.max_size`, the image is scaled to fit the longer edge\n",
    "    to :obj:`self.max_size`.\n",
    "\n",
    "    After resizing the image, the image is subtracted by a mean image value\n",
    "    :obj:`self.mean`.\n",
    "\n",
    "    Args:\n",
    "        img (~numpy.ndarray): An image. This is in CHW and RGB format.\n",
    "            The range of its value is :math:`[0, 255]`.\n",
    "         (~numpy.ndarray): An image. This is in CHW and RGB format.\n",
    "            The range of its value is :math:`[0, 255]`.\n",
    "\n",
    "    Returns:\n",
    "        ~numpy.ndarray:\n",
    "        A preprocessed image.\n",
    "\n",
    "    \"\"\"\n",
    "    C, H, W = img.shape\n",
    "    scale1 = min_size / min(H, W)\n",
    "    scale2 = max_size / max(H, W)\n",
    "    scale = min(scale1, scale2)\n",
    "    img = img / 255.\n",
    "\n",
    "    img = sktsf.resize(img, (C, H * scale, W * scale), mode='reflect')\n",
    "    # both the longer and shorter should be less than\n",
    "    # max_size and min_size\n",
    "\n",
    "    # Only using pytorch normalize\n",
    "    normalize = pytorch_normalize\n",
    "    return normalize(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829402eb-9628-4509-8f3c-c773f8e0bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(object):\n",
    "    def __init__(self, min_size=600, max_size=1000):\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def __call__(self, in_data):\n",
    "        img, bbox, label = in_data\n",
    "        _, H, W = img.shape\n",
    "        img = preprocess(img, self.min_size, self.max_size)\n",
    "        _, o_H, o_W = img.shape\n",
    "        scale = o_H / H\n",
    "        bbox = resize_bbox(bbox, (H, W), (o_H, o_W))\n",
    "\n",
    "        # # horizontally flip\n",
    "        img, params = random_flip(img, x_random=True, return_param=True)\n",
    "        bbox = flip_bbox(bbox, (o_H, o_W), x_flip=params['x_flip'])\n",
    "\n",
    "        return img, bbox, label, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c2a8e8-860f-4e31-9755-aadc78acdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for wider face\n",
    "class Dataset:\n",
    "    def __init__(self, label_dir, data_dir, fname_mat, min_size=600, max_size=1000):\n",
    "        self.db = WIDERBboxDataset(label_dir, data_dir, fname_mat)\n",
    "        self.tsf = Transform(min_size, max_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ori_img, bbox, label, difficult = self.db.get_example(idx)\n",
    "\n",
    "        img, bbox, label, scale = self.tsf((ori_img, bbox, label))\n",
    "        # TODO: check whose stride is negative to fix this instead copy all\n",
    "        # some of the strides of a given numpy array are negative.\n",
    "        return img.copy(), bbox.copy(), label.copy(), scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40038222-e20b-4a2d-8946-f3c76a5bc459",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f360f3-ef19-4abd-b2b0-4c30e644fc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f1b2217cf90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils import data as data_\n",
    "\n",
    "# opt\n",
    "wider_label_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/wider_face_split'\n",
    "wider_data_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/WIDER_train/images'\n",
    "wider_fname_mat = 'wider_face_train'\n",
    "num_workers = 1\n",
    "\n",
    "dataset = Dataset(wider_label_dir, wider_data_dir, wider_fname_mat)\n",
    "dataloader = data_.DataLoader(dataset, \\\n",
    "                              batch_size=1, \\\n",
    "                              shuffle=True, \\\n",
    "                              pin_memory=True,\\\n",
    "                              num_workers=num_workers)\n",
    "dataloader # img, bbox, label, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca2f196b-76f4-4fcc-ad59-9df1c18ae69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inverse_normalize(img):\n",
    "#     return (img * 0.5 + 0.5).clip(min=0, max=1) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5531894-7c85-4e99-85f1-ed9de6a5264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 910, 3)\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(dataloader))\n",
    "# x = np.int32(inverse_normalize(at.tonumpy(x[0].squeeze(0))))\n",
    "print(x[0].squeeze(0).numpy().transpose(1, 2, 0).shape)\n",
    "plt.imshow(x[0].squeeze(0).numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4e1b7-989d-4ab6-9638-37e084caf505",
   "metadata": {},
   "source": [
    "# FasterRCNNVGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8702dca4-d81b-4f09-a8db-fb3f3fe63fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNNVGG16(\n",
       "  (extractor): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (score): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (loc): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (head): VGG16RoIHead(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (cls_loc): Linear(in_features=4096, out_features=8, bias=True)\n",
       "    (score): Linear(in_features=4096, out_features=2, bias=True)\n",
       "    (roi): RoIPooling2D()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.faster_rcnn_vgg16 import FasterRCNNVGG16\n",
    "\n",
    "faster_rcnn = FasterRCNNVGG16()\n",
    "faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2546ff-b2ff-4cc1-ae7d-18230e212dab",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "980afe98-121a-4438-91df-0aca30cbdfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(nn.Module):\n",
    "    def __init__(self, num_channels=3, ngf=100, cg=0.05, learning_rate=1e-4, train_adv=False):\n",
    "        \"\"\"\n",
    "\t\tInitialize a DCGAN. Perturbations from the GAN are added to the inputs to\n",
    "\t\tcreate adversarial attacks.\n",
    "\n",
    "\t\t- num_channels is the number of channels in the input\n",
    "\t\t- ngf is size of the conv layers\n",
    "\t\t- cg is the normalization constant for perturbation (higher means encourage smaller perturbation)\n",
    "\t\t- learning_rate is learning rate for generator optimizer\n",
    "\t\t- train_adv is whether the model being attacked should be trained adversarially\n",
    "\t\t\"\"\"\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            # 3 x 32 x 32\n",
    "            nn.Conv2d(num_channels, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 3 x 32 x32\n",
    "            nn.Conv2d(ngf, num_channels, 1, 1, 0, bias=True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.cuda = t.cuda.is_available()\n",
    "\n",
    "        if self.cuda:\n",
    "            self.generator.cuda()\n",
    "            cudnn.benchmark = True\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "        self.cg = cg\n",
    "        self.optimizer = optim.Adam(self.generator.parameters(), lr=learning_rate)\n",
    "        self.train_adv = train_adv\n",
    "        self.max_iter = 20\n",
    "        self.c_misclassify = 1\n",
    "        self.confidence = 0\n",
    "\n",
    "    def forward(self, inputs, model, labels=None, bboxes=None, scale=None,\\\n",
    "                model_feats=None, model_optimizer=None, *args):\n",
    "        num_unperturbed = 10 # cái này là cái gì???\n",
    "        iter_cnt = 0\n",
    "        loss_perturb = 20\n",
    "        loss_misclassify = 10\n",
    "\n",
    "        while loss_misclassify > 0 and loss_perturb > 1:\n",
    "            perturbation = self.generator(inputs)\n",
    "            adv_inputs = inputs + perturbation\n",
    "            adv_inputs = torch.clamp(adv_inputs, -1.0, 1.0) # giới hạn các pixel trong khoảng -1 dến 1\n",
    "            scores, gt_labels = model(adv_inputs, bboxes, labels, scale, attack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4280f2d7-9321-4501-9a5d-b2cb68c1e007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGAN(\n",
       "  (generator): Sequential(\n",
       "    (0): Conv2d(3, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (10): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (12): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (14): Conv2d(100, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (15): Tanh()\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacker = DCGAN(train_adv=False)\n",
    "attacker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014c70c-2bc5-43b1-ad5e-d2c9689bdf84",
   "metadata": {},
   "source": [
    "# VictimFasterRCNN Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c30b8c-1ea1-43a7-97db-fc0d9e818a8a",
   "metadata": {},
   "source": [
    "# Train VictimFasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d50129-3abd-4642-8afd-f4dd3cfbb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(img):\n",
    "    return (img * 0.5 + 0.5).clip(min=0, max=1) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7589f38-d310-47e5-898e-b039188e5403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(3.4951, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(9.6126, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.9030, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(14.0541, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0595, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6902, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(5.9578e-09, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6941, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.4438, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:05,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6540, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6982, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.6839, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:08,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.5656, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3139, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.8590, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.7697, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:10,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6013, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7046, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.8730, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6300, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6992, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.0112, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:14,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.8305, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.7018, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.6060e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7020, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.2343, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:16,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0289, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.5435, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(7.1503e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7034, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.2758, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:18,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.4955, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(6.8661e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7267, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.2617, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:21,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(2.3182, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(1.5943, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.0009, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7673, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(4.6806, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:23,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.6542, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6348, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.3743e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7148, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.0039, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:26,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.7573, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6539, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(4.2418e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6991, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.1103, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:28,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.1373, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6485, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(3.2968e-08, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6965, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.4823, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:31,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6606, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(6.4990e-08, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6955, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.4440, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:34,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.3198, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6716, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(6.3423e-08, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6955, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.6869, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:36,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6552, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.4643, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6944, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.8196, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:38,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6446, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.6978e-08, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6957, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.3724, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:41,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6345, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.1604e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6960, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.3821, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:43,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0083, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.5740, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6952, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.4996, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:46,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.4759, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6961, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.3037, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:49,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.5341, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.1314e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7008, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:52,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2934, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(4.1157e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7039, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0498, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:53,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3899, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(7.7931e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7058, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.2292, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:54,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.9553, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.8879, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(5.5917e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6969, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.5401, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:56,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.5598, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6961, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.7303, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:57,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0195, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3630, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6976, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.1834, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [01:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(1.0050, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6274, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.0865e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6961, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.3285, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [01:03,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.6796, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6556, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.0720e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6966, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.0318, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [01:04,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.7738, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6869, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(5.1508e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6997, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.1605, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [01:06,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.4109, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.7588e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7004, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.2101, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [01:07,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6177, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.0248e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7033, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.4181, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [01:11,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0186, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2690, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(9.0517e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7019, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(0.9896, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:12,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.4038, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(8.9072e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7006, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.1434, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [01:14,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.7428, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(9.7878e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.7000, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.9644, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [01:15,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6681, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.5761e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6987, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.6246, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [01:18,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3235, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(3.4538e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6976, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0309, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [01:19,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0181, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3831, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.6460e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6971, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0982, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [01:20,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3999, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.2515e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6968, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.1119, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [01:21,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6454, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(4.8309e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6954, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.6813, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [01:23,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0176, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.4170, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.0981e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6965, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.1312, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [01:24,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0183, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3612, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.2563e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6971, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0766, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [01:26,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0263, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3853, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.5721e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6969, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.1085, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [01:27,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6694, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.5417e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6964, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.5326, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [01:28,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2855, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(3.1742e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6967, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(0.9968, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [01:31,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0183, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2343, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(3.5247e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6966, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(0.9491, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [01:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.4968, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.7855, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(7.4814e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6960, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.9783, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [01:34,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0655, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2467, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(9.4874e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6967, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0089, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [01:35,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.5580, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.7756, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.6554e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6954, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.0290, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:37,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0132, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2563, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(4.8868e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6963, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(0.9658, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [01:40,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.1990, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(4.4852e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6963, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(0.9110, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:41,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.7443, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.0416e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6947, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.6304, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:43,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0226, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2169, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(3.8326e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6952, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(0.9348, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [01:45,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.7013, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.8809, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.0388e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6943, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(2.2766, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [01:46,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0275, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2323, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.0894, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6947, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0439, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [01:47,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6267, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.0012e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6942, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.7861, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [01:48,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6557, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(6.1408e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6948, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.5374, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:49,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2589, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(5.0139e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6948, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(0.9901, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [01:52,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0558, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2689, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.2291e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6942, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0189, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [01:53,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6632, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.4581e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6941, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.6469, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [01:54,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2617, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(6.7759e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6954, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(0.9939, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:55,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.3735, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.6735, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(1.9411e-05, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6951, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.7421, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [01:57,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0850, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(9.7749e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6925, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0483, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [01:58,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.1631, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.3903, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(0.0562, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6933, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.3030, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [02:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.1071, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.2846, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(2.7572e-06, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6919, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.0836, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [02:01,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossTuple(rpn_loc_loss=tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), rpn_cls_loss=tensor(0.4470, device='cuda:0', grad_fn=<NllLossBackward0>), roi_loc_loss=tensor(3.2092e-07, device='cuda:0', grad_fn=<DivBackward0>), roi_cls_loss=tensor(0.6920, device='cuda:0', grad_fn=<NllLossBackward0>), total_loss=tensor(1.1739, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [02:04,  1.74s/it]"
     ]
    }
   ],
   "source": [
    "from utils.vis_tool import visdom_bbox\n",
    "\n",
    "trainer = VictimFasterRCNNTrainer(faster_rcnn, attacker).cuda()\n",
    "trainer.vis.text(dataset.db.label_names, win='labels')\n",
    "\n",
    "for epoch in range(20):\n",
    "    trainer.reset_meters()\n",
    "    for ii, (img, bbox_, label_, scale) in tqdm(enumerate(dataloader)):\n",
    "        scale = at.scalar(scale)\n",
    "        img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
    "        img, bbox, label = Variable(img), Variable(bbox), Variable(label)\n",
    "        adv_inputs = trainer.train_step(img, bbox, label, scale)\n",
    "        print(adv_inputs)\n",
    "        \n",
    "        ori_img_ = inverse_normalize(at.tonumpy(img[0]))\n",
    "        gt_img = visdom_bbox(ori_img_,\n",
    "                             at.tonumpy(bbox_[0]),\n",
    "                             at.tonumpy(label_[0]))\n",
    "        trainer.vis.img('gt_img', gt_img)\n",
    "        _bboxes, _labels, _scores = trainer.faster_rcnn.predict([ori_img_], visualize=True)\n",
    "        pred_img = visdom_bbox(ori_img_,\n",
    "                               at.tonumpy(_bboxes[0]),\n",
    "                               at.tonumpy(_labels[0]).reshape(-1),\n",
    "                               at.tonumpy(_scores[0]))\n",
    "        trainer.vis.img('pred_img', pred_img)\n",
    "\n",
    "        # rpn confusion matrix(meter)\n",
    "        trainer.vis.text(str(trainer.rpn_cm.value().tolist()), win='rpn_cm')\n",
    "        # roi confusion matrix\n",
    "        trainer.vis.img('roi_cm', at.totensor(trainer.roi_cm.conf, False).float())\n",
    "        if epoch == 13:\n",
    "            best_path = trainer.save(epochs=epoch)\n",
    "            break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c280d8b8-482f-4bcc-a8e2-b70e9f79b534",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mopt\u001b[49m\u001b[38;5;241m.\u001b[39mepoch):\n\u001b[1;32m      2\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mreset_meters()\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ii, (img, bbox_, label_, scale) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.epoch):\n",
    "    trainer.reset_meters()\n",
    "    for ii, (img, bbox_, label_, scale) in tqdm(enumerate(dataloader)):\n",
    "        scale = at.scalar(scale)\n",
    "        img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
    "        img, bbox, label = Variable(img), Variable(bbox), Variable(label)\n",
    "        losses = trainer.train_step(img, bbox, label, scale)\n",
    "\n",
    "        if (ii + 1) % opt.plot_every == 0:\n",
    "            if os.path.exists(opt.debug_file):\n",
    "                ipdb.set_trace()\n",
    "\n",
    "            # plot loss\n",
    "            trainer.vis.plot_many(trainer.get_meter_data())\n",
    "\n",
    "            # plot groud truth bboxes\n",
    "            ori_img_ = inverse_normalize(at.tonumpy(img[0]))\n",
    "            gt_img = visdom_bbox(ori_img_,\n",
    "                                 at.tonumpy(bbox_[0]),\n",
    "                                 at.tonumpy(label_[0]))\n",
    "            trainer.vis.img('gt_img', gt_img)\n",
    "\n",
    "            # plot predicti bboxes\n",
    "            _bboxes, _labels, _scores = trainer.faster_rcnn.predict([ori_img_], visualize=True)\n",
    "            pred_img = visdom_bbox(ori_img_,\n",
    "                                   at.tonumpy(_bboxes[0]),\n",
    "                                   at.tonumpy(_labels[0]).reshape(-1),\n",
    "                                   at.tonumpy(_scores[0]))\n",
    "            trainer.vis.img('pred_img', pred_img)\n",
    "            _bboxes, _labels, _scores = trainer.faster_rcnn.predict([adv_inputs], visualize=True)\n",
    "            pred_img = visdom_bbox(ori_img_,\n",
    "                                   at.tonumpy(_bboxes[0]),\n",
    "                                   at.tonumpy(_labels[0]).reshape(-1),\n",
    "                                   at.tonumpy(_scores[0]))\n",
    "            trainer.vis.img('adv_img', pred_img)\n",
    "\n",
    "            # rpn confusion matrix(meter)\n",
    "            trainer.vis.text(str(trainer.rpn_cm.value().tolist()), win='rpn_cm')\n",
    "            # roi confusion matrix\n",
    "            trainer.vis.img('roi_cm', at.totensor(trainer.roi_cm.conf, False).float())\n",
    "\n",
    "    #eval_result = eval(test_dataloader, faster_rcnn, test_num=2000)\n",
    "    # if eval_result['map'] > best_map:\n",
    "        # best_map = eval_result['map']\n",
    "        # best_path = trainer.save(best_map=best_map)\n",
    "    # if epoch == 9:\n",
    "        # trainer.load(best_path)\n",
    "        # trainer.faster_rcnn.scale_lr(opt.lr_decay)\n",
    "\n",
    "    # trainer.vis.plot('test_map', eval_result['map'])\n",
    "    # lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "    # log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_),\n",
    "                                              # str(eval_result['map']),\n",
    "                                              # str(trainer.get_meter_data()))\n",
    "    # trainer.vis.log(log_info)\n",
    "    if epoch == 13:\n",
    "        best_path = trainer.save(epochs=epoch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984afe6-0a5e-40de-9dc5-0e785399acc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
