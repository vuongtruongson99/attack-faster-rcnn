{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4b7d86-d633-4f79-b96a-5fbace03e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as tvtsf\n",
    "from skimage import transform as sktsf\n",
    "from data.util import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trainer import VictimFasterRCNNTrainer\n",
    "from utils import array_tool as at\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9756949-00e1-4037-945c-edcb7fcf6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, dtype=np.float32, color=True):\n",
    "    \"\"\"Read an image from a file.\n",
    "\n",
    "    This function reads an image from given file. The image is CHW format and\n",
    "    the range of its value is :math:`[0, 255]`. If :obj:`color = True`, the\n",
    "    order of the channels is RGB.\n",
    "\n",
    "    Args:\n",
    "        path (str): A path of image file.\n",
    "        dtype: The type of array. The default value is :obj:`~numpy.float32`.\n",
    "        color (bool): This option determines the number of channels.\n",
    "            If :obj:`True`, the number of channels is three. In this case,\n",
    "            the order of the channels is RGB. This is the default behaviour.\n",
    "            If :obj:`False`, this function returns a grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        ~numpy.ndarray: An image.\n",
    "    \"\"\"\n",
    "\n",
    "    f = Image.open(path)\n",
    "    try:\n",
    "        if color:\n",
    "            img = f.convert('RGB')\n",
    "        else:\n",
    "            img = f.convert('P')\n",
    "        img = np.asarray(img, dtype=dtype)\n",
    "    finally:\n",
    "        if hasattr(f, 'close'):\n",
    "            f.close()\n",
    "\n",
    "    if img.ndim == 2:\n",
    "        # reshape (H, W) -> (1, H, W)\n",
    "        return img[np.newaxis]\n",
    "    else:\n",
    "        # transpose (H, W, C) -> (C, H, W)\n",
    "        return img.transpose((2, 0, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3366e530-581a-4078-977d-8d34251ca9dd",
   "metadata": {},
   "source": [
    "# Dataset for WIDER FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f438caf-cde5-41b8-b609-d1e6d866fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WIDERBboxDataset:\n",
    "    def __init__(self, path_to_label, path_to_image, fname):\n",
    "        self.path_to_label = path_to_label\n",
    "        self.path_to_image = path_to_image\n",
    "        self.f = scipy.io.loadmat(os.path.join(path_to_label, fname))\n",
    "        self.event_list = self.f.get('event_list')\n",
    "        self.file_list = self.f.get('file_list')\n",
    "        self.face_bbx_list = self.f.get('face_bbx_list')\n",
    "        self.label_names = WIDER_BBOX_LABEL_NAMES\n",
    "        self.im_list, self.bbox_list = self.get_img_list()\n",
    "        # ipdb.set_trace()\n",
    "        self.is_difficult = False\n",
    "\n",
    "    def get_img_list(self):\n",
    "        im_list = []\n",
    "        bbox_list = []\n",
    "        for event_idx, event in enumerate(self.event_list):\n",
    "            directory = event[0][0]\n",
    "            for im_idx, im in enumerate(self.file_list[event_idx][0]):\n",
    "                im_name = im[0][0]\n",
    "                im_list.append(os.path.join(self.path_to_image, directory,\\\n",
    "                        im_name + '.jpg'))\n",
    "                face_bbx = self.face_bbx_list[event_idx][0][im_idx][0]\n",
    "                bbox_list.append(face_bbx)\n",
    "        return im_list,bbox_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_list)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        \"\"\"Returns the i-th example.\n",
    "        Returns a color image and bounding boxes. The image is in CHW format.\n",
    "        The returned image is RGB.\n",
    "\n",
    "        Args:\n",
    "            i (int): The index of the example.\n",
    "\n",
    "        Returns:\n",
    "            tuple of an image and bounding boxes\n",
    "        \"\"\"\n",
    "        # Load a image\n",
    "        img_file = self.im_list[i]\n",
    "        face_bbx = self.bbox_list[i]\n",
    "        img = read_image(img_file, color=True)\n",
    "        bboxes = []\n",
    "        label = []\n",
    "        difficult = []\n",
    "        for i in range(face_bbx.shape[0]):\n",
    "            xmin = int(face_bbx[i][0])\n",
    "            ymin = int(face_bbx[i][1])\n",
    "            xmax = int(face_bbx[i][2]) + xmin\n",
    "            ymax = int(face_bbx[i][3]) + ymin\n",
    "            bboxes.append((ymin, xmin, ymax, xmax))\n",
    "            label.append(WIDER_BBOX_LABEL_NAMES.index('Face'))\n",
    "            difficult.append(self.is_difficult)\n",
    "        bboxes = np.stack(bboxes).astype(np.float32)\n",
    "        label = np.stack(label).astype(np.int32)\n",
    "        difficult = np.array(difficult, dtype=np.bool_).astype(np.uint8)  # PyTorch don't support np.bool\n",
    "        return img, bboxes, label, difficult\n",
    "\n",
    "    __getitem__ = get_example\n",
    "\n",
    "\n",
    "WIDER_BBOX_LABEL_NAMES = (\n",
    "    'Face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fd6264-95da-4fed-bb33-95d936769aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.WIDERBboxDataset at 0x7f765ecaa110>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wider_label_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/wider_face_split'\n",
    "wider_data_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/WIDER_train/images'\n",
    "wider_fname_mat = 'wider_face_train'\n",
    "\n",
    "# Dataset\n",
    "db = WIDERBboxDataset(wider_label_dir, wider_data_dir, wider_fname_mat)\n",
    "db"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d8f2457-5484-4859-bf09-e47fff004205",
   "metadata": {},
   "source": [
    "# Wrapper Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462735e3-06d9-4288-969a-f913990594be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_normalize(img):\n",
    "    \"\"\"\n",
    "    https://github.com/pytorch/vision/issues/223\n",
    "    return appr -1~1 RGB\n",
    "    \"\"\"\n",
    "    # normalize = tvtsf.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                             std=[0.229, 0.224, 0.225])\n",
    "    normalize = tvtsf.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                std=[0.5, 0.5, 0.5])\n",
    "    img = normalize(t.from_numpy(img))\n",
    "    return img.numpy()\n",
    "\n",
    "def preprocess(img, min_size=600, max_size=1000):\n",
    "    \"\"\"Preprocess an image for feature extraction.\n",
    "\n",
    "    The length of the shorter edge is scaled to :obj:`self.min_size`.\n",
    "    After the scaling, if the length of the longer edge is longer than\n",
    "    :param min_size:\n",
    "    :obj:`self.max_size`, the image is scaled to fit the longer edge\n",
    "    to :obj:`self.max_size`.\n",
    "\n",
    "    After resizing the image, the image is subtracted by a mean image value\n",
    "    :obj:`self.mean`.\n",
    "\n",
    "    Args:\n",
    "        img (~numpy.ndarray): An image. This is in CHW and RGB format.\n",
    "            The range of its value is :math:`[0, 255]`.\n",
    "         (~numpy.ndarray): An image. This is in CHW and RGB format.\n",
    "            The range of its value is :math:`[0, 255]`.\n",
    "\n",
    "    Returns:\n",
    "        ~numpy.ndarray:\n",
    "        A preprocessed image.\n",
    "\n",
    "    \"\"\"\n",
    "    C, H, W = img.shape\n",
    "    scale1 = min_size / min(H, W)\n",
    "    scale2 = max_size / max(H, W)\n",
    "    scale = min(scale1, scale2)\n",
    "    img = img / 255.\n",
    "\n",
    "    img = sktsf.resize(img, (C, H * scale, W * scale), mode='reflect')\n",
    "    # both the longer and shorter should be less than\n",
    "    # max_size and min_size\n",
    "\n",
    "    # Only using pytorch normalize\n",
    "    normalize = pytorch_normalize\n",
    "    return normalize(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829402eb-9628-4509-8f3c-c773f8e0bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(object):\n",
    "    def __init__(self, min_size=600, max_size=1000):\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def __call__(self, in_data):\n",
    "        img, bbox, label = in_data\n",
    "        _, H, W = img.shape\n",
    "        img = preprocess(img, self.min_size, self.max_size)\n",
    "        _, o_H, o_W = img.shape\n",
    "        scale = o_H / H\n",
    "        bbox = resize_bbox(bbox, (H, W), (o_H, o_W))\n",
    "        # # horizontally flip\n",
    "        img, params = random_flip(img, x_random=True, return_param=True)\n",
    "        bbox = flip_bbox(bbox, (o_H, o_W), x_flip=params['x_flip'])\n",
    "\n",
    "        return img, bbox, label, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c2a8e8-860f-4e31-9755-aadc78acdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for wider face\n",
    "class Dataset:\n",
    "    def __init__(self, label_dir, data_dir, fname_mat, min_size=600, max_size=1000):\n",
    "        self.db = WIDERBboxDataset(label_dir, data_dir, fname_mat)\n",
    "        self.tsf = Transform(min_size, max_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ori_img, bbox, label, difficult = self.db.get_example(idx)\n",
    "\n",
    "        img, bbox, label, scale = self.tsf((ori_img, bbox, label))\n",
    "        # TODO: check whose stride is negative to fix this instead copy all\n",
    "        # some of the strides of a given numpy array are negative.\n",
    "        return img.copy(), bbox.copy(), label.copy(), scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6c8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestDataset:\n",
    "    def __init__(self, wider_label_dir, wider_val_data_dir, wider_val_fname_mat, split='test', use_difficult=True):\n",
    "        self.db = WIDERBboxDataset(wider_label_dir, wider_val_data_dir, wider_val_fname_mat)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ori_img, bbox, label, difficult = self.db.get_example(idx)\n",
    "        img = preprocess(ori_img)\n",
    "        return img, ori_img.shape[1:], bbox, label, difficult\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40038222-e20b-4a2d-8946-f3c76a5bc459",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f360f3-ef19-4abd-b2b0-4c30e644fc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f753c3b2450>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils import data as data_\n",
    "\n",
    "# opt\n",
    "wider_train_label_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/wider_face_split'\n",
    "wider_train_data_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/WIDER_train/images'\n",
    "wider_train_fname_mat = 'wider_face_train'\n",
    "\n",
    "num_workers = 1\n",
    "\n",
    "dataset = Dataset(wider_train_label_dir, wider_train_data_dir, wider_train_fname_mat)\n",
    "dataloader = data_.DataLoader(dataset, \\\n",
    "                              batch_size=1, \\\n",
    "                              shuffle=True, \\\n",
    "                              pin_memory=True,\\\n",
    "                              num_workers=num_workers)\n",
    "dataloader # img, bbox, label, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5531894-7c85-4e99-85f1-ed9de6a5264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = next(iter(dataloader))\n",
    "# # x = np.int32(inverse_normalize(at.tonumpy(x[0].squeeze(0))))\n",
    "# print(x[0].squeeze(0).numpy().transpose(1, 2, 0).shape)\n",
    "# plt.imshow(x[0].squeeze(0).numpy().transpose(1, 2, 0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4ac158b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f753c3b1150>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils import data as data_\n",
    "\n",
    "# opt\n",
    "wider_val_label_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/wider_face_split'\n",
    "wider_val_data_dir = '/home/son/Desktop/Research/simple-faster-rcnn-pytorch/data/WIDER_val/images'\n",
    "wider_val_fname_mat = 'wider_face_val'\n",
    "\n",
    "num_workers = 1\n",
    "\n",
    "testset = TestDataset(wider_val_label_dir, wider_val_data_dir, wider_val_fname_mat)\n",
    "test_dataloader = data_.DataLoader(testset, \\\n",
    "                                batch_size=1, \\\n",
    "                                shuffle=True, \\\n",
    "                                pin_memory=True,\\\n",
    "                                num_workers=num_workers)\n",
    "test_dataloader # img, bbox, label, scale"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92a4e1b7-989d-4ab6-9638-37e084caf505",
   "metadata": {},
   "source": [
    "# FasterRCNNVGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8702dca4-d81b-4f09-a8db-fb3f3fe63fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained VGG16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNNVGG16(\n",
       "  (extractor): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (score): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (loc): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (head): VGG16RoIHead(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (cls_loc): Linear(in_features=4096, out_features=8, bias=True)\n",
       "    (score): Linear(in_features=4096, out_features=2, bias=True)\n",
       "    (roi): RoIPooling2D()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.faster_rcnn_vgg16 import FasterRCNNVGG16\n",
    "\n",
    "faster_rcnn = FasterRCNNVGG16()\n",
    "faster_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "febe6ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster_rcnn.extractor[28].state_dict()['weight'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "014414fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster_rcnn.extractor[0].state_dict()['weight'].size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df2546ff-b2ff-4cc1-ae7d-18230e212dab",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "980afe98-121a-4438-91df-0aca30cbdfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(nn.Module):\n",
    "    def __init__(self, num_channels=3, ngf=100, cg=0.05, learning_rate=1e-4, train_adv=False):\n",
    "        \"\"\"\n",
    "\t\tInitialize a DCGAN. Perturbations from the GAN are added to the inputs to\n",
    "\t\tcreate adversarial attacks.\n",
    "\n",
    "\t\t- num_channels is the number of channels in the input\n",
    "\t\t- ngf is size of the conv layers\n",
    "\t\t- cg is the normalization constant for perturbation (higher means encourage smaller perturbation)\n",
    "\t\t- learning_rate is learning rate for generator optimizer\n",
    "\t\t- train_adv is whether the model being attacked should be trained adversarially\n",
    "\t\t\"\"\"\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            # 3 x 32 x 32\n",
    "            nn.Conv2d(num_channels, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 1000 x 32 x 32\n",
    "            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 3 x 32 x32\n",
    "            nn.Conv2d(ngf, num_channels, 1, 1, 0, bias=True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.cuda = t.cuda.is_available()\n",
    "\n",
    "        if self.cuda:\n",
    "            self.generator.cuda()\n",
    "            cudnn.benchmark = True\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "        self.cg = cg\n",
    "        self.optimizer = optim.Adam(self.generator.parameters(), lr=learning_rate)\n",
    "        self.train_adv = train_adv\n",
    "        self.max_iter = 20\n",
    "        self.c_misclassify = 1\n",
    "        self.confidence = 0\n",
    "\n",
    "    def forward(self, inputs, model, labels=None, bboxes=None, scale=None,\\\n",
    "                model_feats=None, model_optimizer=None, *args):\n",
    "        num_unperturbed = 10 # cái này là cái gì???\n",
    "        iter_cnt = 0\n",
    "        loss_perturb = 20\n",
    "        loss_misclassify = 10\n",
    "\n",
    "        while loss_misclassify > 0 and loss_perturb > 1:\n",
    "            perturbation = self.generator(inputs)\n",
    "            adv_inputs = inputs + perturbation\n",
    "            adv_inputs = t.clamp(adv_inputs, -1.0, 1.0) # giới hạn các pixel trong khoảng -1 dến 1\n",
    "            scores, gt_labels = model(adv_inputs, bboxes, labels, scale, attack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4280f2d7-9321-4501-9a5d-b2cb68c1e007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGAN(\n",
       "  (generator): Sequential(\n",
       "    (0): Conv2d(3, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (10): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (12): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (14): Conv2d(100, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (15): Tanh()\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacker = DCGAN(train_adv=False)\n",
    "attacker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e014c70c-2bc5-43b1-ad5e-d2c9689bdf84",
   "metadata": {},
   "source": [
    "# VictimFasterRCNN Trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7c30b8c-1ea1-43a7-97db-fc0d9e818a8a",
   "metadata": {},
   "source": [
    "# Train VictimFasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d50129-3abd-4642-8afd-f4dd3cfbb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_tool import eval_detection_voc\n",
    "\n",
    "def inverse_normalize(img):\n",
    "    return (img * 0.5 + 0.5).clip(min=0, max=1) * 255\n",
    "\n",
    "def eval(dataloader, faster_rcnn, test_num=100):\n",
    "    pred_bboxes, pred_labels, pred_scores = list(), list(), list()\n",
    "    gt_bboxes, gt_labels, gt_difficults = list(), list(), list()\n",
    "\n",
    "    for ii, (imgs, sizes, gt_bboxes_, gt_labels_, gt_difficults_) in tqdm(enumerate(dataloader),total=test_num):\n",
    "        sizes = [sizes[0][0], sizes[1][0]]\n",
    "\n",
    "        try:\n",
    "            pred_bboxes_, pred_labels_, pred_scores_ = faster_rcnn.predict(imgs, [sizes])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        gt_bboxes += list(gt_bboxes_.numpy())\n",
    "        gt_labels += list(gt_labels_.numpy())\n",
    "        gt_difficults += list(gt_difficults_.numpy())\n",
    "        pred_bboxes += pred_bboxes_\n",
    "        pred_labels += pred_labels_\n",
    "        pred_scores += pred_scores_\n",
    "        if ii == test_num: break\n",
    "\n",
    "    result = eval_detection_voc(\n",
    "        pred_bboxes, pred_labels, pred_scores,\n",
    "        gt_bboxes, gt_labels, gt_difficults,\n",
    "        use_07_metric=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7589f38-d310-47e5-898e-b039188e5403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m img, bbox, label \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mcuda()\u001b[39m.\u001b[39mfloat(), bbox_\u001b[39m.\u001b[39mcuda(), label_\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     14\u001b[0m img, bbox, label \u001b[39m=\u001b[39m Variable(img), Variable(bbox), Variable(label)\n\u001b[0;32m---> 15\u001b[0m adv_inputs \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain_step(img, bbox, label, scale)\n\u001b[1;32m     17\u001b[0m \u001b[39m# ori_img_ = inverse_normalize(at.tonumpy(img[0]))\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# gt_img = visdom_bbox(ori_img_,\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m#                      at.tonumpy(bbox_[0]),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m# rpn confusion matrix(meter)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m trainer\u001b[39m.\u001b[39mvis\u001b[39m.\u001b[39mtext(\u001b[39mstr\u001b[39m(trainer\u001b[39m.\u001b[39mrpn_cm\u001b[39m.\u001b[39mvalue()\u001b[39m.\u001b[39mtolist()), win\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrpn_cm\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Research/simple-faster-rcnn-pytorch/trainer.py:436\u001b[0m, in \u001b[0;36mVictimFasterRCNNTrainer.train_step\u001b[0;34m(self, imgs, bboxes, labels, scale)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattack_mode:\n\u001b[1;32m    435\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 436\u001b[0m     losses  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(imgs, bboxes, labels, scale)\n\u001b[1;32m    437\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m         losses\u001b[39m.\u001b[39mtotal_loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/Research/simple-faster-rcnn-pytorch/trainer.py:338\u001b[0m, in \u001b[0;36mVictimFasterRCNNTrainer.forward\u001b[0;34m(self, imgs, bboxes, labels, scale, attack)\u001b[0m\n\u001b[1;32m    336\u001b[0m _, _, H, W \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mshape\n\u001b[1;32m    337\u001b[0m img_size \u001b[39m=\u001b[39m (H, W)\n\u001b[0;32m--> 338\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfaster_rcnn\u001b[39m.\u001b[39;49mextractor(imgs)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39m(features\u001b[39m.\u001b[39msize()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    341\u001b[0m     rpn_locs, rpn_scores, rois, roi_indices, anchor \u001b[39m=\u001b[39m \\\n\u001b[1;32m    342\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfaster_rcnn\u001b[39m.\u001b[39mrpn(features, img_size, scale)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo8/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo8/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo8/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo8/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo8/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection to remote host was lost.\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "[Errno 111] Connection refused\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from utils.vis_tool import visdom_bbox\n",
    "\n",
    "\n",
    "trainer = VictimFasterRCNNTrainer(faster_rcnn, attacker).cuda()\n",
    "trainer.vis.text(dataset.db.label_names, win='labels')\n",
    "lr_decay = 0.1\n",
    "\n",
    "for epoch in range(20):\n",
    "    trainer.reset_meters()\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{20}\", leave=False)\n",
    "    for ii, (img, bbox_, label_, scale) in enumerate(progress_bar):\n",
    "        scale = at.scalar(scale)\n",
    "        img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
    "        img, bbox, label = Variable(img), Variable(bbox), Variable(label)\n",
    "        adv_inputs = trainer.train_step(img, bbox, label, scale)\n",
    "        \n",
    "        # ori_img_ = inverse_normalize(at.tonumpy(img[0]))\n",
    "        # gt_img = visdom_bbox(ori_img_,\n",
    "        #                      at.tonumpy(bbox_[0]),\n",
    "        #                      at.tonumpy(label_[0]))\n",
    "        # trainer.vis.img('gt_img', gt_img)\n",
    "        # _bboxes, _labels, _scores = trainer.faster_rcnn.predict([ori_img_], visualize=True)\n",
    "        # pred_img = visdom_bbox(ori_img_,\n",
    "        #                        at.tonumpy(_bboxes[0]),\n",
    "        #                        at.tonumpy(_labels[0]).reshape(-1),\n",
    "        #                        at.tonumpy(_scores[0]))\n",
    "        # trainer.vis.img('pred_img', pred_img)\n",
    "\n",
    "        # rpn confusion matrix(meter)\n",
    "        trainer.vis.text(str(trainer.rpn_cm.value().tolist()), win='rpn_cm')\n",
    "        # roi confusion matrix\n",
    "        trainer.vis.img('roi_cm', at.totensor(trainer.roi_cm.conf, False).float())\n",
    "    \n",
    "    eval_result = eval(test_dataloader, faster_rcnn, test_num=2000)\n",
    "    if eval_result['map'] > best_map:\n",
    "        best_map = eval_result['map']\n",
    "        best_path = trainer.save(best_map=best_map)\n",
    "    if epoch == 9:\n",
    "        trainer.load(best_path)\n",
    "        trainer.faster_rcnn.scale_lr(lr_decay)\n",
    "\n",
    "    trainer.vis.plot('test_map', eval_result['map'])\n",
    "    lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "    log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_),\n",
    "                                                str(eval_result['map']),\n",
    "                                                str(trainer.get_meter_data()))\n",
    "    trainer.vis.log(log_info)\n",
    "    \n",
    "    if epoch == 13:\n",
    "        best_path = trainer.save(epochs=epoch)\n",
    "        break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280d8b8-482f-4bcc-a8e2-b70e9f79b534",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mopt\u001b[49m\u001b[38;5;241m.\u001b[39mepoch):\n\u001b[1;32m      2\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mreset_meters()\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ii, (img, bbox_, label_, scale) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.epoch):\n",
    "    trainer.reset_meters()\n",
    "    for ii, (img, bbox_, label_, scale) in tqdm(enumerate(dataloader)):\n",
    "        scale = at.scalar(scale)\n",
    "        img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
    "        img, bbox, label = Variable(img), Variable(bbox), Variable(label)\n",
    "        losses = trainer.train_step(img, bbox, label, scale)\n",
    "\n",
    "        if (ii + 1) % opt.plot_every == 0:\n",
    "            if os.path.exists(opt.debug_file):\n",
    "                ipdb.set_trace()\n",
    "\n",
    "            # plot loss\n",
    "            trainer.vis.plot_many(trainer.get_meter_data())\n",
    "\n",
    "            # plot groud truth bboxes\n",
    "            ori_img_ = inverse_normalize(at.tonumpy(img[0]))\n",
    "            gt_img = visdom_bbox(ori_img_,\n",
    "                                 at.tonumpy(bbox_[0]),\n",
    "                                 at.tonumpy(label_[0]))\n",
    "            trainer.vis.img('gt_img', gt_img)\n",
    "\n",
    "            # plot predicti bboxes\n",
    "            _bboxes, _labels, _scores = trainer.faster_rcnn.predict([ori_img_], visualize=True)\n",
    "            pred_img = visdom_bbox(ori_img_,\n",
    "                                   at.tonumpy(_bboxes[0]),\n",
    "                                   at.tonumpy(_labels[0]).reshape(-1),\n",
    "                                   at.tonumpy(_scores[0]))\n",
    "            trainer.vis.img('pred_img', pred_img)\n",
    "            _bboxes, _labels, _scores = trainer.faster_rcnn.predict([adv_inputs], visualize=True)\n",
    "            pred_img = visdom_bbox(ori_img_,\n",
    "                                   at.tonumpy(_bboxes[0]),\n",
    "                                   at.tonumpy(_labels[0]).reshape(-1),\n",
    "                                   at.tonumpy(_scores[0]))\n",
    "            trainer.vis.img('adv_img', pred_img)\n",
    "\n",
    "            # rpn confusion matrix(meter)\n",
    "            trainer.vis.text(str(trainer.rpn_cm.value().tolist()), win='rpn_cm')\n",
    "            # roi confusion matrix\n",
    "            trainer.vis.img('roi_cm', at.totensor(trainer.roi_cm.conf, False).float())\n",
    "\n",
    "    #eval_result = eval(test_dataloader, faster_rcnn, test_num=2000)\n",
    "    # if eval_result['map'] > best_map:\n",
    "        # best_map = eval_result['map']\n",
    "        # best_path = trainer.save(best_map=best_map)\n",
    "    # if epoch == 9:\n",
    "        # trainer.load(best_path)\n",
    "        # trainer.faster_rcnn.scale_lr(opt.lr_decay)\n",
    "\n",
    "    # trainer.vis.plot('test_map', eval_result['map'])\n",
    "    # lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
    "    # log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_),\n",
    "                                              # str(eval_result['map']),\n",
    "                                              # str(trainer.get_meter_data()))\n",
    "    # trainer.vis.log(log_info)\n",
    "    if epoch == 13:\n",
    "        best_path = trainer.save(epochs=epoch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984afe6-0a5e-40de-9dc5-0e785399acc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad74af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
